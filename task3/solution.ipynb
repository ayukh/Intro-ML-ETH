{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "614c49d3",
   "metadata": {
    "papermill": {
     "duration": 0.004166,
     "end_time": "2023-05-03T12:02:59.771789",
     "exception": false,
     "start_time": "2023-05-03T12:02:59.767623",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gustas\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "572cc07f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T12:02:59.781723Z",
     "iopub.status.busy": "2023-05-03T12:02:59.780807Z",
     "iopub.status.idle": "2023-05-03T12:03:04.820431Z",
     "shell.execute_reply": "2023-05-03T12:03:04.819616Z"
    },
    "papermill": {
     "duration": 5.047069,
     "end_time": "2023-05-03T12:03:04.822798",
     "exception": false,
     "start_time": "2023-05-03T12:02:59.775729",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DataLoader, TensorDataset\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnn\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import models\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "# from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc9ebae",
   "metadata": {
    "papermill": {
     "duration": 0.003776,
     "end_time": "2023-05-03T12:03:04.830506",
     "exception": false,
     "start_time": "2023-05-03T12:03:04.826730",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Get Data + EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f619d2da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T12:03:04.840532Z",
     "iopub.status.busy": "2023-05-03T12:03:04.839648Z",
     "iopub.status.idle": "2023-05-03T12:03:04.852842Z",
     "shell.execute_reply": "2023-05-03T12:03:04.851719Z"
    },
    "papermill": {
     "duration": 0.02097,
     "end_time": "2023-05-03T12:03:04.855134",
     "exception": false,
     "start_time": "2023-05-03T12:03:04.834164",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 9.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def generate_embeddings(batch_size=64):\n",
    "    \"\"\"\n",
    "    Transform, resize and normalize the images and then use a pretrained model to extract \n",
    "    the embeddings.\n",
    "    \"\"\"\n",
    "    # Check if GPU is available\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    \n",
    "    # TODO: define a transform to pre-process the images\n",
    "    train_transforms = transforms.Compose([\n",
    "    torchvision.transforms.Resize(232),\n",
    "    torchvision.transforms.CenterCrop(224),\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "    torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "]) # tune this\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(root=\"/kaggle/input/imltask3/dataset/dataset/\", transform=train_transforms)\n",
    "    # Hint: adjust batch_size and num_workers to your PC configuration, so that you don't \n",
    "    # run out of memory\n",
    "    train_loader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=batch_size, # tune this\n",
    "                              shuffle=False,\n",
    "                              pin_memory=True, num_workers=2)\n",
    "    # TODO: define a model for extraction of the embeddings (Hint: load a pretrained model,\n",
    "    #  more info here: https://pytorch.org/vision/stable/models.html)\n",
    "    model = resnet50(weights=\"IMAGENET1K_V2\")\n",
    "    # model.to(device)\n",
    "\n",
    "    embeddings = []\n",
    "    embedding_size = list(model.children())[-1].in_features # 2048\n",
    "    num_images = len(train_dataset)\n",
    "    embeddings = np.zeros((num_images, embedding_size))\n",
    "\n",
    "    # TODO: Use the model to extract the embeddings. Hint: remove the last layers of the \n",
    "    # model to access the embeddings the model generates.\n",
    "     \n",
    "    model.eval() \n",
    "\n",
    "    model = nn.Sequential(*list(model.children())[:-1]) # remove last layer of the model\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for batch_idx, (image, image_idx) in enumerate(tqdm(train_loader)):\n",
    "            embed_features = model(image) # get features from pretrained model  \n",
    "            embed_features = embed_features.squeeze().cpu().numpy() # get to shape (256, 2048)\n",
    "            embeddings[batch_idx * train_loader.batch_size : (batch_idx + 1) * train_loader.batch_size] = embed_features           \n",
    "            \n",
    "    np.save(f'embeddings_{batch_size}.npy', embeddings)\n",
    "    \n",
    "#generate_embeddings(batch_size=64) # -> both embeddings code and modelling do not work bc of memory issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6d638fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T12:03:04.864622Z",
     "iopub.status.busy": "2023-05-03T12:03:04.864217Z",
     "iopub.status.idle": "2023-05-03T12:03:21.558368Z",
     "shell.execute_reply": "2023-05-03T12:03:21.557260Z"
    },
    "papermill": {
     "duration": 16.702039,
     "end_time": "2023-05-03T12:03:21.561007",
     "exception": false,
     "start_time": "2023-05-03T12:03:04.858968",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59515/59515 [00:06<00:00, 9273.97it/s]\n",
      "100%|██████████| 59544/59544 [00:02<00:00, 21902.60it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_data(file, train=True):\n",
    "    \"\"\"\n",
    "    Load the triplets from the file and generate the features and labels.\n",
    "\n",
    "    input: file: string, the path to the file containing the triplets\n",
    "          train: boolean, whether the data is for training or testing\n",
    "\n",
    "    output: X: numpy array, the features\n",
    "            y: numpy array, the labels\n",
    "    \"\"\"\n",
    "    triplets = []\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            triplets.append(line)\n",
    "\n",
    "    # generate training data from tripletsfiles = os.listdir(os.path.join(inputfolder,'dataset/food'))\n",
    "    #files = os.listdir(os.path.join('dataset/food'))\n",
    "    #filenames = [s[0].split('/')[-1].replace('.jpg', '') for s in train_dataset.samples]\n",
    "    \n",
    "    filenames = np.loadtxt(\"/kaggle/input/imltask3/filenames.txt\", dtype=str) # if run on kaggle\n",
    "    embeddings = np.load('/kaggle/input/imltask3/embeddings_64.npy') # if run on kaggle\n",
    "    # TODO: Normalize the embeddings across the dataset\n",
    "    \n",
    "    embeddings = (embeddings - np.mean(embeddings, axis=0)) / np.std(embeddings, axis=0)\n",
    "    \n",
    "    file_to_embedding = {}\n",
    "    for i in range(len(filenames)):\n",
    "        file_name = filenames[i]\n",
    "        file_to_embedding[file_name] = embeddings[i]\n",
    "        \n",
    "    X = []\n",
    "    y = []\n",
    "    # use the individual embeddings to generate the features and labels for triplets\n",
    "    for t in tqdm(triplets):\n",
    "        emb = [file_to_embedding[a] for a in t.split()]\n",
    "        X.append(np.hstack([emb[0], emb[1], emb[2]]))\n",
    "        y.append(1)\n",
    "        # Generating negative samples (data augmentation) \n",
    "            # -> basically swap image1 with image2 which will get output 0\n",
    "                # can we augment it even more? (not sure)\n",
    "        if train:\n",
    "            X.append(np.hstack([emb[0], emb[2], emb[1]]))\n",
    "            y.append(0)\n",
    "    X = np.vstack(X)\n",
    "    y = np.hstack(y)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "TRAIN_TRIPLETS = '/kaggle/input/imltask3/train_triplets.txt'\n",
    "TEST_TRIPLETS = '/kaggle/input/imltask3/test_triplets.txt'\n",
    "\n",
    "X, y = get_data(TRAIN_TRIPLETS)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "X_train = X_train.reshape(-1, 512, 4, 3) # resize to 4dTensor for CNNs, maybe correct shape is (-1, 256, 6, 4), not sure\n",
    "X_valid = X_valid.reshape(-1, 512, 4, 3)\n",
    "X_test, _ = get_data(TEST_TRIPLETS, train=False)\n",
    "X_test = X_test.reshape(-1, 512, 4, 3) # resize to 4dTensor for CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1980317",
   "metadata": {
    "papermill": {
     "duration": 0.008955,
     "end_time": "2023-05-03T12:03:21.579368",
     "exception": false,
     "start_time": "2023-05-03T12:03:21.570413",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50c597bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T12:03:21.599587Z",
     "iopub.status.busy": "2023-05-03T12:03:21.599192Z",
     "iopub.status.idle": "2023-05-03T12:03:23.415236Z",
     "shell.execute_reply": "2023-05-03T12:03:23.413638Z"
    },
    "papermill": {
     "duration": 1.832274,
     "end_time": "2023-05-03T12:03:23.420890",
     "exception": false,
     "start_time": "2023-05-03T12:03:21.588616",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data\n",
      "Load data\n",
      "Load data\n"
     ]
    }
   ],
   "source": [
    "# Hint: adjust batch_size and num_workers to your PC configuration, so that you don't run out of memory\n",
    "def create_loader_from_np(X, y = None, train = True, batch_size=64, shuffle=True, num_workers = 2):\n",
    "    \"\"\"\n",
    "    Create a torch.utils.data.DataLoader object from numpy arrays containing the data.\n",
    "\n",
    "    input: X: numpy array, the features\n",
    "           y: numpy array, the labels\n",
    "    \n",
    "    output: loader: torch.data.util.DataLoader, the object containing the data\n",
    "    \"\"\"\n",
    "    print(\"Load data\")\n",
    "    if train:\n",
    "        dataset = TensorDataset(torch.from_numpy(X).type(torch.float),\n",
    "                                torch.from_numpy(y).type(torch.long))\n",
    "    else:\n",
    "        dataset = TensorDataset(torch.from_numpy(X).type(torch.float))\n",
    "    loader = DataLoader(dataset=dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=shuffle,\n",
    "                        num_workers=num_workers)\n",
    "    return loader\n",
    "\n",
    "\n",
    "train_loader = create_loader_from_np(X_train, y_train, train = True, batch_size=64)\n",
    "valid_loader = create_loader_from_np(X_valid, y_valid, train = True, batch_size=64)\n",
    "test_loader = create_loader_from_np(X_test, train = False, batch_size=2048, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b894323d",
   "metadata": {
    "papermill": {
     "duration": 0.012964,
     "end_time": "2023-05-03T12:03:23.445041",
     "exception": false,
     "start_time": "2023-05-03T12:03:23.432077",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "224c74f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T12:03:23.486201Z",
     "iopub.status.busy": "2023-05-03T12:03:23.484565Z",
     "iopub.status.idle": "2023-05-03T12:16:38.636295Z",
     "shell.execute_reply": "2023-05-03T12:16:38.634712Z"
    },
    "papermill": {
     "duration": 795.175038,
     "end_time": "2023-05-03T12:16:38.639867",
     "exception": false,
     "start_time": "2023-05-03T12:03:23.464829",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cpu\n",
      "Train model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1488/1488 [00:27<00:00, 54.81batch/s, Train loss=1.11, Train accuracy=49.9]\n",
      "Epoch 0 valid: 100%|██████████| 372/372 [00:04<00:00, 82.43batch/s, Val loss=0.727, Val accuracy=56.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train accuracy:  0.4991674467165899 Final valid accuracy:  0.5403280003468609 \n",
      " Final train loss:  1.1141511398137256 Final valid loss:  0.6979516062044329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1488/1488 [00:25<00:00, 57.36batch/s, Train loss=0.668, Train accuracy=58.7]\n",
      "Epoch 1 valid: 100%|██████████| 372/372 [00:04<00:00, 82.07batch/s, Val loss=0.64, Val accuracy=59.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train accuracy:  0.5873745919738863 Final valid accuracy:  0.6200518123482484 \n",
      " Final train loss:  0.6677557157092197 Final valid loss:  0.6466286764029534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1488/1488 [00:26<00:00, 56.71batch/s, Train loss=0.582, Train accuracy=69.3]\n",
      "Epoch 2 valid: 100%|██████████| 372/372 [00:04<00:00, 84.37batch/s, Val loss=0.562, Val accuracy=69.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train accuracy:  0.6931388608870968 Final valid accuracy:  0.6734033558792923 \n",
      " Final train loss:  0.5821019595348706 Final valid loss:  0.6069528619127889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1488/1488 [00:25<00:00, 57.50batch/s, Train loss=0.486, Train accuracy=77.1]\n",
      "Epoch 3 valid: 100%|██████████| 372/372 [00:04<00:00, 84.00batch/s, Val loss=0.486, Val accuracy=80.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train accuracy:  0.7707103254608294 Final valid accuracy:  0.6927760796045785 \n",
      " Final train loss:  0.48586895290802246 Final valid loss:  0.6050834413818134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1488/1488 [00:26<00:00, 55.57batch/s, Train loss=0.411, Train accuracy=81.8]\n",
      "Epoch 4 valid: 100%|██████████| 372/372 [00:04<00:00, 84.23batch/s, Val loss=0.55, Val accuracy=74.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train accuracy:  0.8183893769201229 Final valid accuracy:  0.7051614529136316 \n",
      " Final train loss:  0.4107482868336862 Final valid loss:  0.6179060280643484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1488/1488 [00:26<00:00, 55.87batch/s, Train loss=0.35, Train accuracy=85.1]\n",
      "Epoch 5 valid: 100%|██████████| 372/372 [00:04<00:00, 89.32batch/s, Val loss=0.827, Val accuracy=66.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train accuracy:  0.8511814756144394 Final valid accuracy:  0.7136812239854318 \n",
      " Final train loss:  0.3495948625508175 Final valid loss:  0.6437288710987696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1488/1488 [00:27<00:00, 54.01batch/s, Train loss=0.302, Train accuracy=87.7]\n",
      "Epoch 6 valid: 100%|██████████| 372/372 [00:04<00:00, 83.20batch/s, Val loss=0.501, Val accuracy=77.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train accuracy:  0.8766261040706606 Final valid accuracy:  0.7168409100763093 \n",
      " Final train loss:  0.3018526255042963 Final valid loss:  0.6832120048422967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1488/1488 [00:28<00:00, 51.82batch/s, Train loss=0.266, Train accuracy=89.2]\n",
      "Epoch 7 valid: 100%|██████████| 372/372 [00:04<00:00, 80.42batch/s, Val loss=0.548, Val accuracy=74.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train accuracy:  0.8922676051267282 Final valid accuracy:  0.7173002297953521 \n",
      " Final train loss:  0.26593262714243704 Final valid loss:  0.6989588066134401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1488/1488 [00:27<00:00, 54.21batch/s, Train loss=0.234, Train accuracy=90.6]\n",
      "Epoch 8 valid: 100%|██████████| 372/372 [00:04<00:00, 81.69batch/s, Val loss=0.906, Val accuracy=71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train accuracy:  0.9062590005760369 Final valid accuracy:  0.7242699661810613 \n",
      " Final train loss:  0.2342899080806522 Final valid loss:  0.7306952746484869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1488/1488 [00:27<00:00, 54.76batch/s, Train loss=0.211, Train accuracy=91.7]\n",
      "Epoch 9 valid: 100%|██████████| 372/372 [00:04<00:00, 87.14batch/s, Val loss=0.916, Val accuracy=66.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train accuracy:  0.917481218798003 Final valid accuracy:  0.7244339121574748 \n",
      " Final train loss:  0.21085796939078918 Final valid loss:  0.8072539254702548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1488/1488 [00:27<00:00, 53.46batch/s, Train loss=0.192, Train accuracy=92.6]\n",
      "Epoch 10 valid: 100%|██████████| 372/372 [00:04<00:00, 80.31batch/s, Val loss=0.844, Val accuracy=72.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train accuracy:  0.9261877760176652 Final valid accuracy:  0.7215411463753035 \n",
      " Final train loss:  0.19209286501450884 Final valid loss:  0.8079299578262914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 1488/1488 [00:27<00:00, 54.42batch/s, Train loss=0.175, Train accuracy=93.2]\n",
      "Epoch 11 valid: 100%|██████████| 372/372 [00:04<00:00, 83.19batch/s, Val loss=0.743, Val accuracy=75.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train accuracy:  0.9322961669546852 Final valid accuracy:  0.7259541384842179 \n",
      " Final train loss:  0.17513658704676777 Final valid loss:  0.8573889221234988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 1488/1488 [00:27<00:00, 54.48batch/s, Train loss=0.162, Train accuracy=93.8]\n",
      "Epoch 12 valid: 100%|██████████| 372/372 [00:04<00:00, 82.25batch/s, Val loss=0.655, Val accuracy=77.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train accuracy:  0.9379110263056836 Final valid accuracy:  0.7297357353451266 \n",
      " Final train loss:  0.16197765754005042 Final valid loss:  0.8835401846676745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 1488/1488 [00:28<00:00, 52.74batch/s, Train loss=0.151, Train accuracy=94.2]\n",
      "Epoch 13 valid: 100%|██████████| 372/372 [00:04<00:00, 79.81batch/s, Val loss=1.33, Val accuracy=67.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train accuracy:  0.9418322772657449 Final valid accuracy:  0.7311976998785987 \n",
      " Final train loss:  0.15050168927528604 Final valid loss:  0.9272585861304755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1488/1488 [00:27<00:00, 53.91batch/s, Train loss=0.138, Train accuracy=94.7]\n",
      "Epoch 14 valid: 100%|██████████| 372/372 [00:04<00:00, 82.46batch/s, Val loss=0.885, Val accuracy=75.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train accuracy:  0.9466430851574501 Final valid accuracy:  0.7326325659035726 \n",
      " Final train loss:  0.13849456700551455 Final valid loss:  0.966915198631825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 1488/1488 [00:27<00:00, 53.58batch/s, Train loss=0.131, Train accuracy=95]\n",
      "Epoch 15 valid: 100%|██████████| 372/372 [00:04<00:00, 82.92batch/s, Val loss=0.562, Val accuracy=75.8] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train accuracy:  0.9496042746735791 Final valid accuracy:  0.7350267191293791 \n",
      " Final train loss:  0.13100036441458648 Final valid loss:  0.971000129977862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 1488/1488 [00:26<00:00, 55.79batch/s, Train loss=0.123, Train accuracy=95.2]\n",
      "Epoch 16 valid: 100%|██████████| 372/372 [00:04<00:00, 75.33batch/s, Val loss=1.18, Val accuracy=72.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train accuracy:  0.9524064540130568 Final valid accuracy:  0.7358640630419703 \n",
      " Final train loss:  0.12269722472848771 Final valid loss:  1.013488343806677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 1488/1488 [00:26<00:00, 55.22batch/s, Train loss=0.112, Train accuracy=95.7]\n",
      "Epoch 17 valid: 100%|██████████| 372/372 [00:04<00:00, 80.54batch/s, Val loss=1.33, Val accuracy=69.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train accuracy:  0.9571512576804916 Final valid accuracy:  0.7378774822233785 \n",
      " Final train loss:  0.11241775937628762 Final valid loss:  1.0761979512309516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 1488/1488 [00:27<00:00, 54.02batch/s, Train loss=0.108, Train accuracy=95.9]\n",
      "Epoch 18 valid: 100%|██████████| 372/372 [00:04<00:00, 83.70batch/s, Val loss=1.38, Val accuracy=67.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train accuracy:  0.9590638800883255 Final valid accuracy:  0.7362380224592439 \n",
      " Final train loss:  0.1076417356236307 Final valid loss:  1.0942960467229608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 1488/1488 [00:27<00:00, 53.57batch/s, Train loss=0.102, Train accuracy=96.1]\n",
      "Epoch 19 valid: 100%|██████████| 372/372 [00:04<00:00, 85.02batch/s, Val loss=1.71, Val accuracy=62.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train accuracy:  0.961083009312596 Final valid accuracy:  0.7408542533818938 \n",
      " Final train loss:  0.10183031230937109 Final valid loss:  1.1140297974950524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 1488/1488 [00:27<00:00, 54.84batch/s, Train loss=0.0956, Train accuracy=96.3]\n",
      "Epoch 20 valid: 100%|██████████| 372/372 [00:04<00:00, 82.42batch/s, Val loss=1.74, Val accuracy=61.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train accuracy:  0.9629251272081413 Final valid accuracy:  0.737912710284426 \n",
      " Final train loss:  0.0956017475015664 Final valid loss:  1.111335364240472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 1488/1488 [00:27<00:00, 53.30batch/s, Train loss=0.0909, Train accuracy=96.5]\n",
      "Epoch 21 valid: 100%|██████████| 372/372 [00:04<00:00, 85.35batch/s, Val loss=0.997, Val accuracy=74.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train accuracy:  0.9649757584485407 Final valid accuracy:  0.7399816814082553 \n",
      " Final train loss:  0.09088393964589403 Final valid loss:  1.1457781229288346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 1488/1488 [00:27<00:00, 54.08batch/s, Train loss=0.0874, Train accuracy=96.7]\n",
      "Epoch 22 valid: 100%|██████████| 372/372 [00:04<00:00, 82.90batch/s, Val loss=0.691, Val accuracy=85.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train accuracy:  0.9672784058179724 Final valid accuracy:  0.7387730879292405 \n",
      " Final train loss:  0.08736964350538728 Final valid loss:  1.2097297619267176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 1488/1488 [00:29<00:00, 50.56batch/s, Train loss=0.0829, Train accuracy=96.8]\n",
      "Epoch 23 valid: 100%|██████████| 372/372 [00:04<00:00, 89.09batch/s, Val loss=1.07, Val accuracy=79] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train accuracy:  0.9683344734062981 Final valid accuracy:  0.7417918617759279 \n",
      " Final train loss:  0.08288672706675565 Final valid loss:  1.2233328933837593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1488/1488 [00:26<00:00, 56.41batch/s, Train loss=0.0789, Train accuracy=97]\n",
      "Epoch 24 valid: 100%|██████████| 372/372 [00:04<00:00, 84.88batch/s, Val loss=2.19, Val accuracy=61.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train accuracy:  0.9703401017665132 Final valid accuracy:  0.7415669441553937 \n",
      " Final train loss:  0.07893469357726625 Final valid loss:  1.2627274866706582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: define a model. Here, the basic structure is defined, but you need to fill in the details\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    The model class, which defines our classifier.\n",
    "    \"\"\"\n",
    "    def __init__(self, dropout=True, dropout_p=0.4):\n",
    "        \"\"\"\n",
    "        The constructor of the model.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.convlayer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=128, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.convlayer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=1, stride=1)\n",
    "        )\n",
    "        self.convlayer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=8, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=1, stride=1)\n",
    "        )\n",
    "        \n",
    "        self.fullycon1 = nn.Sequential(nn.Linear(8 * 2 * 1, 120), nn.ReLU())\n",
    "        self.fullycon2 = nn.Sequential(nn.Linear(120, 84), nn.ReLU())\n",
    "        if dropout:\n",
    "            self.fullycon3 = nn.Sequential(nn.Dropout(p=dropout_p), nn.Linear(84, 64))\n",
    "        else:\n",
    "            self.fullycon3 = nn.Linear(84, 64)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        The forward pass of the model.\n",
    "\n",
    "        input: x: torch.Tensor, the input to the model\n",
    "\n",
    "        output: x: torch.Tensor, the output of the model\n",
    "        \"\"\"\n",
    "        x = self.convlayer1(x)\n",
    "        x = self.convlayer2(x)\n",
    "        x = self.convlayer3(x)\n",
    "        x = x.view(-1, 8 * 2 * 1)\n",
    "        x = self.fullycon1(x)\n",
    "        x = self.fullycon2(x)\n",
    "        x = self.fullycon3(x)\n",
    "        return x\n",
    "\n",
    "def train_model(train_loader):\n",
    "    \"\"\"\n",
    "    The training procedure of the model; it accepts the training data, defines the model \n",
    "    and then trains it.\n",
    "\n",
    "    input: train_loader: torch.data.util.DataLoader, the object containing the training data\n",
    "    \n",
    "    output: model: torch.nn.Module, the trained model\n",
    "    \"\"\"\n",
    "    model = Net()\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    print('device: ', device)\n",
    "    n_epochs = 25 # tune this\n",
    "    batch_size = 256 # and this\n",
    "\n",
    "    losses = []\n",
    "    acc = []\n",
    "    valid_losses = []\n",
    "    valid_acc = []\n",
    "    # TODO: define a loss function, optimizer and proceed with training. Hint: use the part \n",
    "    # of the training data as a validation split. After each epoch, compute the loss on the \n",
    "    # validation\n",
    "    # split and print it out. This enables you to see how your model is performing \n",
    "    # on the validation data before submitting the results on the server. After choosing the \n",
    "    # best model, train it on the whole training data.\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4) # tune lr\n",
    "\n",
    "    print(\"Train model\")\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss_epoch = []\n",
    "        train_acc_epoch = []\n",
    "        valid_loss_epoch = []\n",
    "        valid_acc_epoch = []\n",
    "        with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "            for data, target in tepoch:\n",
    "                tepoch.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                predictions = output.argmax(dim=1, keepdim=True).squeeze()\n",
    "                loss = criterion(output, target)\n",
    "                train_loss_epoch.append(loss.item())\n",
    "                correct = (predictions == target).sum().item()\n",
    "                accuracy = correct / len(predictions)\n",
    "                train_acc_epoch.append(accuracy)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss_avg = np.sum(train_loss_epoch) / len(train_loss_epoch)\n",
    "                train_acc_avg = np.sum(train_acc_epoch) / len(train_acc_epoch)\n",
    "                tepoch.set_postfix({'Train loss': train_loss_avg, 'Train accuracy': 100. * train_acc_avg})\n",
    "                \n",
    "            with torch.no_grad():\n",
    "                with tqdm(valid_loader, unit=\"batch\") as tepoch:\n",
    "                    for valid_data, valid_target in tepoch:\n",
    "                        tepoch.set_description(f\"Epoch {epoch} valid\")\n",
    "                        valid_data, valid_target = valid_data.to(device), valid_target.to(device)\n",
    "                        valid_output = model(valid_data)\n",
    "                        valid_predictions = valid_output.argmax(dim=1, keepdim=True).squeeze()\n",
    "                        valid_loss = criterion(valid_output, valid_target)\n",
    "                        valid_loss_epoch.append(valid_loss.item())\n",
    "                        valid_correct = (valid_predictions == valid_target).sum().item()\n",
    "                        valid_accuracy = valid_correct / len(valid_predictions)\n",
    "                        valid_acc_epoch.append(valid_accuracy)\n",
    "                        \n",
    "                        valid_loss_avg = np.sum(valid_loss_epoch) / len(valid_loss_epoch)\n",
    "                        valid_acc_avg = np.sum(valid_acc_epoch) / len(valid_acc_epoch)\n",
    "                        tepoch.set_postfix({'Val loss': valid_loss.item(), 'Val accuracy': 100. * valid_accuracy})\n",
    "        \n",
    "        losses.append(train_loss_avg)\n",
    "        acc.append(train_acc_avg)\n",
    "        valid_losses.append(valid_loss_avg)\n",
    "        valid_acc.append(valid_acc_avg)\n",
    "        \n",
    "        print('Final train accuracy: ', train_acc_avg, 'Final valid accuracy: ', valid_acc_avg,\n",
    "             '\\n Final train loss: ', train_loss_avg, 'Final valid loss: ', valid_loss_avg)\n",
    "        \n",
    "    return model, losses, acc, valid_losses, valid_acc\n",
    "\n",
    "model, losses, acc, valid_losses, valid_acc = train_model(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a11afe55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T12:16:51.881352Z",
     "iopub.status.busy": "2023-05-03T12:16:51.880224Z",
     "iopub.status.idle": "2023-05-03T12:16:52.186531Z",
     "shell.execute_reply": "2023-05-03T12:16:52.185513Z"
    },
    "papermill": {
     "duration": 7.03369,
     "end_time": "2023-05-03T12:16:52.189016",
     "exception": false,
     "start_time": "2023-05-03T12:16:45.155326",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.20.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"0a555baa-67a5-44a6-a871-dd4552b14bcf\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0a555baa-67a5-44a6-a871-dd4552b14bcf\")) {                    Plotly.newPlot(                        \"0a555baa-67a5-44a6-a871-dd4552b14bcf\",                        [{\"connectgaps\":true,\"name\":\"Train Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[1.1141511398137256,0.6677557157092197,0.5821019595348706,0.48586895290802246,0.4107482868336862,0.3495948625508175,0.3018526255042963,0.26593262714243704,0.2342899080806522,0.21085796939078918,0.19209286501450884,0.17513658704676777,0.16197765754005042,0.15050168927528604,0.13849456700551455,0.13100036441458648,0.12269722472848771,0.11241775937628762,0.1076417356236307,0.10183031230937109,0.0956017475015664,0.09088393964589403,0.08736964350538728,0.08288672706675565,0.07893469357726625],\"type\":\"scatter\"},{\"name\":\"Train Accuracy\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.4991674467165899,0.5873745919738863,0.6931388608870968,0.7707103254608294,0.8183893769201229,0.8511814756144394,0.8766261040706606,0.8922676051267282,0.9062590005760369,0.917481218798003,0.9261877760176652,0.9322961669546852,0.9379110263056836,0.9418322772657449,0.9466430851574501,0.9496042746735791,0.9524064540130568,0.9571512576804916,0.9590638800883255,0.961083009312596,0.9629251272081413,0.9649757584485407,0.9672784058179724,0.9683344734062981,0.9703401017665132],\"type\":\"scatter\"},{\"connectgaps\":true,\"name\":\"Valid Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.6979516062044329,0.6466286764029534,0.6069528619127889,0.6050834413818134,0.6179060280643484,0.6437288710987696,0.6832120048422967,0.6989588066134401,0.7306952746484869,0.8072539254702548,0.8079299578262914,0.8573889221234988,0.8835401846676745,0.9272585861304755,0.966915198631825,0.971000129977862,1.013488343806677,1.0761979512309516,1.0942960467229608,1.1140297974950524,1.111335364240472,1.1457781229288346,1.2097297619267176,1.2233328933837593,1.2627274866706582],\"type\":\"scatter\"},{\"name\":\"Valid Accuracy\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.5403280003468609,0.6200518123482484,0.6734033558792923,0.6927760796045785,0.7051614529136316,0.7136812239854318,0.7168409100763093,0.7173002297953521,0.7242699661810613,0.7244339121574748,0.7215411463753035,0.7259541384842179,0.7297357353451266,0.7311976998785987,0.7326325659035726,0.7350267191293791,0.7358640630419703,0.7378774822233785,0.7362380224592439,0.7408542533818938,0.737912710284426,0.7399816814082553,0.7387730879292405,0.7417918617759279,0.7415669441553937],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('0a555baa-67a5-44a6-a871-dd4552b14bcf');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x,\n",
    "    y=losses,\n",
    "    name = 'Train Loss',\n",
    "    connectgaps=True\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x,\n",
    "    y=acc,\n",
    "    name='Train Accuracy',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x,\n",
    "    y=valid_losses,\n",
    "    name = 'Valid Loss',\n",
    "    connectgaps=True\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x,\n",
    "    y=valid_acc,\n",
    "    name='Valid Accuracy',\n",
    "))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7297fae",
   "metadata": {
    "papermill": {
     "duration": 6.733169,
     "end_time": "2023-05-03T12:17:05.508280",
     "exception": false,
     "start_time": "2023-05-03T12:16:58.775111",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0989bf9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T12:17:18.690848Z",
     "iopub.status.busy": "2023-05-03T12:17:18.690410Z",
     "iopub.status.idle": "2023-05-03T12:17:22.437913Z",
     "shell.execute_reply": "2023-05-03T12:17:22.436419Z"
    },
    "papermill": {
     "duration": 10.314836,
     "end_time": "2023-05-03T12:17:22.440437",
     "exception": false,
     "start_time": "2023-05-03T12:17:12.125601",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results.txt\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, loader):\n",
    "    \"\"\"\n",
    "    The testing procedure of the model; it accepts the testing data and the trained model and \n",
    "    then tests the model on it.\n",
    "\n",
    "    input: model: torch.nn.Module, the trained model\n",
    "           loader: torch.data.util.DataLoader, the object containing the testing data\n",
    "        \n",
    "    output: None, the function saves the predictions to a results.txt file\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    # Iterate over the test data\n",
    "    with torch.no_grad(): # We don't need to compute gradients for testing\n",
    "        for [x_batch] in loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            predicted = model(x_batch)\n",
    "            predicted = predicted.argmax(dim=1, keepdim=True).squeeze().cpu().numpy()\n",
    "            predicted[predicted >= 0.5] = 1\n",
    "            predicted[predicted < 0.5] = 0\n",
    "            predictions.append(predicted)\n",
    "        predictions = np.hstack(predictions)\n",
    "    np.savetxt(\"results.txt\", predictions, fmt='%i')\n",
    "    \n",
    "test_model(model, test_loader)\n",
    "print(\"Results saved to results.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 883.034508,
   "end_time": "2023-05-03T12:17:32.492486",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-03T12:02:49.457978",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}